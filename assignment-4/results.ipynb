{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from AdaBoostClassifier import AdaBoostClassifier\n",
    "from DecisionTree import decision_tree_classifier, Criterion\n",
    "from RandomForest import RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "d = pd.read_csv(\n",
    "    \"data/train.csv\")[['Age', 'Sex', 'Fare', 'Pclass', 'Survived','PassengerId']].dropna()\n",
    "d = d.assign(Sex=d.Sex.eq('male').astype(int))\n",
    "\n",
    "\n",
    "# Constructing the X and Y matrices\n",
    "X = d[['Age', 'Sex', 'Fare', 'Pclass','PassengerId']]\n",
    "Y = d['Survived'].values.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>3</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>3</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Sex      Fare  Pclass  PassengerId\n",
       "328  31.0    0   20.5250       3          329\n",
       "73   26.0    1   14.4542       3           74\n",
       "253  30.0    1   16.1000       3          254\n",
       "719  33.0    1    7.7750       3          720\n",
       "666  25.0    1   13.0000       2          667\n",
       "..    ...  ...       ...     ...          ...\n",
       "92   46.0    1   61.1750       1           93\n",
       "134  25.0    1   13.0000       2          135\n",
       "337  41.0    0  134.5000       1          338\n",
       "548  33.0    1   20.5250       3          549\n",
       "130  33.0    1    7.8958       3          131\n",
       "\n",
       "[571 rows x 5 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "def get_accuracy(yhat,y_test):\n",
    "    yhat = yhat.tolist()\n",
    "\n",
    "    same = 0\n",
    "    for i in range(len(yhat)):\n",
    "        if yhat[i] == y_test[i]:\n",
    "            same += 1\n",
    "\n",
    "    print(f\"ACCURACY: {same/len(yhat):.5f}\")\n",
    "    return same/len(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Classifier\n",
      "ACCURACY: 0.73427\n"
     ]
    }
   ],
   "source": [
    "print(\"Ada Boost Classifier\")\n",
    "ab = AdaBoostClassifier(5, 0.001)\n",
    "ab.fit(X_train, y_train)\n",
    "# Predicting\n",
    "\n",
    "yhat = ab.predict(X_test)\n",
    "accuracy_scores.append((\"Ada Boost Classifier\",get_accuracy(yhat,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier - ENTROPY\n",
      "Root\n",
      "-------- Split rule: Sex <= 0.5\n",
      "---------------- Split rule: Pclass <= 2.5\n",
      "------------------------ Split rule: PassengerId <= 362.5\n",
      "-------------------------------- Split rule: Age <= 2.5\n",
      "-------------------------------- Split rule: Age > 2.5\n",
      "---------------------------------------- Split rule: Fare <= 28.856\n",
      "---------------------------------------- Split rule: Fare > 28.856\n",
      "------------------------ Split rule: PassengerId > 362.5\n",
      "-------------------------------- Split rule: PassengerId <= 854.5\n",
      "-------------------------------- Split rule: PassengerId > 854.5\n",
      "---------------------------------------- Split rule: PassengerId <= 856.0\n",
      "---------------------------------------- Split rule: PassengerId > 856.0\n",
      "---------------- Split rule: Pclass > 2.5\n",
      "------------------------ Split rule: Age <= 27.5\n",
      "-------------------------------- Split rule: Fare <= 23.087\n",
      "---------------------------------------- Split rule: Age <= 6.5\n",
      "---------------------------------------- Split rule: Age > 6.5\n",
      "-------------------------------- Split rule: Fare > 23.087\n",
      "------------------------ Split rule: Age > 27.5\n",
      "-------------------------------- Split rule: Age <= 55.5\n",
      "---------------------------------------- Split rule: Age <= 38.5\n",
      "---------------------------------------- Split rule: Age > 38.5\n",
      "-------------------------------- Split rule: Age > 55.5\n",
      "-------- Split rule: Sex > 0.5\n",
      "---------------- Split rule: Age <= 3.5\n",
      "------------------------ Split rule: Fare <= 29.062\n",
      "------------------------ Split rule: Fare > 29.062\n",
      "---------------- Split rule: Age > 3.5\n",
      "------------------------ Split rule: Pclass <= 1.5\n",
      "-------------------------------- Split rule: Age <= 52.5\n",
      "---------------------------------------- Split rule: PassengerId <= 384.5\n",
      "---------------------------------------- Split rule: PassengerId > 384.5\n",
      "-------------------------------- Split rule: Age > 52.5\n",
      "---------------------------------------- Split rule: PassengerId <= 572.0\n",
      "---------------------------------------- Split rule: PassengerId > 572.0\n",
      "------------------------ Split rule: Pclass > 1.5\n",
      "-------------------------------- Split rule: Age <= 45.25\n",
      "---------------------------------------- Split rule: Age <= 44.5\n",
      "---------------------------------------- Split rule: Age > 44.5\n",
      "-------------------------------- Split rule: Age > 45.25\n",
      "ACCURACY: 0.77622\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTree Classifier - ENTROPY\")\n",
    "dt = decision_tree_classifier(\n",
    "    Criterion.ENTROPY, min_samples_split=10, max_depth=5, min_samples_leaf=1)\n",
    "root_node = dt.fit(X_train, y_train)\n",
    "dt.print_tree(root_node)\n",
    "\n",
    "# Predicting\n",
    "\n",
    "yhat = dt.predict(X_test)\n",
    "accuracy_scores.append((\"DecisionTree Classifier - ENTROPY\",get_accuracy(yhat,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier - MISCLASSIFICATION\n",
      "Root\n",
      "-------- Split rule: Sex <= 0.5\n",
      "---------------- Split rule: Fare <= 6.988\n",
      "---------------- Split rule: Fare > 6.988\n",
      "-------- Split rule: Sex > 0.5\n",
      "---------------- Split rule: Age <= 3.5\n",
      "------------------------ Split rule: Fare <= 39.344\n",
      "-------------------------------- Split rule: PassengerId <= 48.0\n",
      "-------------------------------- Split rule: PassengerId > 48.0\n",
      "------------------------ Split rule: Fare > 39.344\n",
      "---------------- Split rule: Age > 3.5\n",
      "------------------------ Split rule: Age <= 77.0\n",
      "-------------------------------- Split rule: Fare <= 387.665\n",
      "-------------------------------- Split rule: Fare > 387.665\n",
      "------------------------ Split rule: Age > 77.0\n",
      "ACCURACY: 0.75524\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTree Classifier - MISCLASSIFICATION\")\n",
    "dt = decision_tree_classifier(\n",
    "    Criterion.MISCLASSIFICATION_RATE, min_samples_split=10, max_depth=5, min_samples_leaf=1)\n",
    "root_node = dt.fit(X_train, y_train)\n",
    "dt.print_tree(root_node)\n",
    "\n",
    "# Predicting\n",
    "\n",
    "yhat = dt.predict(X_test)\n",
    "accuracy_scores.append((\"DecisionTree Classifier - MISCLASSIFICATION\",get_accuracy(yhat,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier - GINI IMPURITY\n",
      "Root\n",
      "-------- Split rule: Sex <= 0.5\n",
      "---------------- Split rule: Pclass <= 2.5\n",
      "------------------------ Split rule: PassengerId <= 362.5\n",
      "-------------------------------- Split rule: Age <= 2.5\n",
      "-------------------------------- Split rule: Age > 2.5\n",
      "---------------------------------------- Split rule: Fare <= 28.856\n",
      "---------------------------------------- Split rule: Fare > 28.856\n",
      "------------------------ Split rule: PassengerId > 362.5\n",
      "-------------------------------- Split rule: PassengerId <= 854.5\n",
      "-------------------------------- Split rule: PassengerId > 854.5\n",
      "---------------------------------------- Split rule: PassengerId <= 856.0\n",
      "---------------------------------------- Split rule: PassengerId > 856.0\n",
      "---------------- Split rule: Pclass > 2.5\n",
      "------------------------ Split rule: Age <= 27.5\n",
      "-------------------------------- Split rule: Fare <= 23.087\n",
      "---------------------------------------- Split rule: Age <= 6.5\n",
      "---------------------------------------- Split rule: Age > 6.5\n",
      "-------------------------------- Split rule: Fare > 23.087\n",
      "------------------------ Split rule: Age > 27.5\n",
      "-------------------------------- Split rule: Age <= 55.5\n",
      "---------------------------------------- Split rule: Age <= 38.5\n",
      "---------------------------------------- Split rule: Age > 38.5\n",
      "-------------------------------- Split rule: Age > 55.5\n",
      "-------- Split rule: Sex > 0.5\n",
      "---------------- Split rule: Age <= 3.5\n",
      "------------------------ Split rule: Fare <= 29.062\n",
      "------------------------ Split rule: Fare > 29.062\n",
      "---------------- Split rule: Age > 3.5\n",
      "------------------------ Split rule: Pclass <= 1.5\n",
      "-------------------------------- Split rule: Age <= 52.5\n",
      "---------------------------------------- Split rule: PassengerId <= 384.5\n",
      "---------------------------------------- Split rule: PassengerId > 384.5\n",
      "-------------------------------- Split rule: Age > 52.5\n",
      "---------------------------------------- Split rule: PassengerId <= 572.0\n",
      "---------------------------------------- Split rule: PassengerId > 572.0\n",
      "------------------------ Split rule: Pclass > 1.5\n",
      "-------------------------------- Split rule: Age <= 45.25\n",
      "---------------------------------------- Split rule: Age <= 44.5\n",
      "---------------------------------------- Split rule: Age > 44.5\n",
      "-------------------------------- Split rule: Age > 45.25\n",
      "ACCURACY: 0.77622\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTree Classifier - GINI IMPURITY\")\n",
    "dt = decision_tree_classifier(\n",
    "    Criterion.ENTROPY, min_samples_split=10, max_depth=5, min_samples_leaf=1)\n",
    "root_node = dt.fit(X_train, y_train)\n",
    "dt.print_tree(root_node)\n",
    "\n",
    "# Predicting\n",
    "\n",
    "yhat = dt.predict(X_test)\n",
    "accuracy_scores.append((\"DecisionTree Classifier - GINI IMPURITY\",get_accuracy(yhat,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM-FOREST - using decision tree classifier - GINI IMPURITY\n",
      "['Fare', 'PassengerId']\n",
      "['Pclass', 'Fare', 'Age', 'PassengerId']\n",
      "['PassengerId', 'Fare', 'Age', 'Pclass', 'Sex']\n",
      "['Sex', 'Age', 'Fare', 'Pclass']\n",
      "['Age', 'Sex', 'Fare', 'PassengerId', 'Pclass']\n",
      "ACCURACY: 0.60839\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM-FOREST - using decision tree classifier - GINI IMPURITY\")\n",
    "rf = RandomForest(dt,num_trees = 5,min_features = 2)\n",
    "rf.fit(X,Y)\n",
    "yhat = rf.predict(X_test)\n",
    "accuracy_scores.append((\"RANDOM-FOREST - using decision tree classifier - GINI IMPURITY\",get_accuracy(yhat,y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM-FOREST - using ada boost classifier\n",
      "['Fare', 'Pclass', 'Age', 'PassengerId']\n",
      "['Age', 'PassengerId', 'Pclass']\n",
      "['Fare', 'Sex', 'Pclass', 'PassengerId', 'Age']\n",
      "['PassengerId', 'Fare', 'Age', 'Sex']\n",
      "['PassengerId', 'Sex', 'Pclass', 'Age', 'Fare']\n",
      "ACCURACY: 0.61538\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM-FOREST - using ada boost classifier\")\n",
    "rf = RandomForest(ab,num_trees = 5,min_features = 2)\n",
    "rf.fit(X,Y)\n",
    "yhat = rf.predict(X_test)\n",
    "accuracy_scores.append((\"RANDOM-FOREST - using ada boost classifier\",get_accuracy(yhat,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.734266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree Classifier - ENTROPY</td>\n",
       "      <td>0.776224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree Classifier - MISCLASSIFICATION</td>\n",
       "      <td>0.755245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree Classifier - GINI IMPURITY</td>\n",
       "      <td>0.776224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM-FOREST - using decision tree classifier...</td>\n",
       "      <td>0.608392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RANDOM-FOREST - using ada boost classifier</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Method    Scores\n",
       "0                               Ada Boost Classifier  0.734266\n",
       "1                  DecisionTree Classifier - ENTROPY  0.776224\n",
       "2        DecisionTree Classifier - MISCLASSIFICATION  0.755245\n",
       "3            DecisionTree Classifier - GINI IMPURITY  0.776224\n",
       "4  RANDOM-FOREST - using decision tree classifier...  0.608392\n",
       "5         RANDOM-FOREST - using ada boost classifier  0.615385"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(accuracy_scores)\n",
    "names = []\n",
    "scores = []\n",
    "for name,accuracy in accuracy_scores:\n",
    "    names.append(name)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(\"\")\n",
    "import pandas as pd\n",
    "data = {\"Method\":names,\"Scores\":scores}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
